# -*- coding: utf-8 -*-
"""HACKATHON-117.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fe0DW_2EQvKwc4ffU20nACzGfBDghkXe

#Problem Statement
 **Detecting fraud for transactions in a payment gateway.

 **IndAvenue has started gaining traction due to its extremely low processing fees for handling online vendorsâ€™ digital payments.

 **This strategy has led to very low costs of acquiring new vendors.
  
  **is_fruad is the target varible in tha data
"""

#importing libraries
import pandas as pd
import numpy as np

#reading the data
train_data=pd.read_csv("/content/train_data-1611220940820.csv",na_values='?' ',')

train_data.head()

"""#Understand the data"""

rows,cols=train_data.shape
print(f'There are {rows} Rows and {cols} Columns')

train_data.info()

train_data.columns

train_data.dtypes

train_data.describe()

#finding null values
train_data.isnull().sum()

#unique values in target variable
train_data['is_fraud'].value_counts()

train_data['partner_id'].nunique()

train_data.value_counts('partner_id')

"""#EDA(Exploratory Data Analysis)"""

import matplotlib.pyplot as plt
import seaborn as sns

#Heat map
plt.figure(figsize = (18, 12))
sns.heatmap(data =train_data.corr(), annot = True, fmt ='.2g', linewidth = 1)
plt.show()

train_data_f=train_data[train_data['is_fraud']==1]
train_data_nf=train_data[train_data['is_fraud']==0]

train_data_f.head()

plt.figure(figsize=(10,10))
sns.countplot(train_data_f.device_type)
plt.title("Fraud claims based on device type")
plt.show()

plt.figure(figsize=(10,10))
sns.countplot(train_data_f.partner_category)
plt.title("Fraud claims based on partner category")
plt.show()

from matplotlib.pyplot import subplots
train_data.plot(kind='hist',subplots=True,sharex=False,sharey=False,layout=(3,3),figsize=(13,13))
plt.show()

train_data.plot(kind='density',subplots=True,sharex=False,sharey=False,layout=(3,3),figsize=(13,13))
plt.show()

train_data.plot(kind='box',subplots=True,sharex=False,sharey=False,layout=(3,3),figsize=(13,13))
plt.show()

"""#Feature engineering
 
 **Coverting transaction_initiation into date & time data type
"""

train_data['transaction_initiation'] = pd.to_datetime(train_data['transaction_initiation'])
train_data['transaction_initiation'].dtypes

train_data['year'] = train_data['transaction_initiation'].dt.year
train_data['month'] = train_data['transaction_initiation'].dt.month
train_data['day'] = train_data['transaction_initiation'].dt.day
train_data['time'] = train_data['transaction_initiation'].dt.time
train_data.drop(columns='transaction_initiation', axis='1', inplace=True)

train_data.head()

train_data.dtypes

train_data.head()

train_data=train_data.drop("time",axis=1)
train_data.head()

train_data.dtypes

"""#preprocessing"""

cat_attr=(["payment_method","partner_category","device_type"])
train_data[cat_attr]=train_data[cat_attr].astype('category')

train_data.dtypes

train_data=train_data.drop(['transaction_number','country'],axis=1)
train_data.head()

"""#Encoding"""

train_data=pd.get_dummies(train_data)

train_data.columns

train_data.shape

"""# Spliting the data"""

from sklearn.model_selection import train_test_split
y=train_data["is_fraud"]
x=train_data.drop("is_fraud",axis=1)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

"""## Standardize the data"""

num_art=x_train.select_dtypes(['int64','float64']).columns
num_art_test=x_test.select_dtypes(['int64','float64']).columns
print(num_art)
print(num_art_test)

from sklearn.preprocessing import StandardScaler

scaler=StandardScaler()
x_train[num_art]=scaler.fit_transform(x_train[num_art])
x_test[num_art_test]=scaler.fit_transform(x_test[num_art])

print(x_train[num_art].shape)
print(x_test[num_art_test].shape)

"""#Building models"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from xgboost.sklearn import XGBClassifier

import statistics as stat

model1=KNeighborsClassifier()
model2=LogisticRegression()
model3=DecisionTreeClassifier()
model4=RandomForestClassifier()
model5=XGBClassifier()

model1.fit(x_train,y_train)
model2.fit(x_train,y_train)
model3.fit(x_train,y_train)
model4.fit(x_train,y_train)
model5.fit(x_train,y_train)

train_prds1=model1.predict(x_train)
train_prds2=model2.predict(x_train)
train_prds3=model3.predict(x_train)
train_prds4=model4.predict(x_train)
train_prds5=model5.predict(x_train)

test_prds1=model1.predict(x_test)
test_prds2=model2.predict(x_test)
test_prds3=model3.predict(x_test)
test_prds4=model4.predict(x_test)
test_prds5=model5.predict(x_test)

from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score

print('========Train=======')
print(f"Confusion Matrix of KNN \n{confusion_matrix(y_train, train_prds1)}")
print('========Train=======')
print(f"Confusion Matrix of LR \n{confusion_matrix(y_train, train_prds2)}")
print('========Train=======')
print(f"Confusion Matrix of DT \n{confusion_matrix(y_train, train_prds3)}")
print('========Train=======')
print(f"Confusion Matrix of RFC \n{confusion_matrix(y_train, train_prds4)}")
print('========Train=======')
print(f"Confusion Matrix of XGB \n{confusion_matrix(y_train, train_prds5)}")

print('========Test=======')
print(f"Confusion Matrix of KNN \n{confusion_matrix(y_test, test_prds1)}")
print('========Test=======')
print(f"Confusion Matrix of LR \n{confusion_matrix(y_test, test_prds2)}")
print('========Test=======')
print(f"Confusion Matrix of DT \n{confusion_matrix(y_test, test_prds3)}")
print('========Test=======')
print(f"Confusion Matrix of RFC \n{confusion_matrix(y_test, test_prds4)}")
print('========Test=======')
print(f"Confusion Matrix of XGB \n{confusion_matrix(y_test, test_prds5)}")

print("train f1_score of KNeighborsClassifier :",f1_score (y_train,train_prds1,))
print("train f1_score of LogisticRegression :", f1_score(y_train,train_prds2))
print("train f1_score of DecisionTreeClassifier :" ,f1_score(y_train,train_prds3))
print("train f1_score of RandomForestClassifier :" ,f1_score(y_train,train_prds4))
print("train f1_score of XGBClassifier :" ,f1_score(y_train,train_prds5))

print("test f1_score of KNeighborsClassifier :" ,f1_score(y_test,test_prds1))
print("test f1_score of LogisticRegression :" ,f1_score(y_test,test_prds2))
print("test f1_score of DecisionTreeClassifier :" ,f1_score(y_test,test_prds3))
print("test f1_score of RandomForestClassifier :" ,f1_score(y_test,test_prds4))
print("train f1_score of XGBClassifier :" ,f1_score(y_test,test_prds5))

"""#Test Dataset

"""

test_data=pd.read_csv("/content/test_data-1611220982388.csv")

test_data.head()

test_data.columns

test_data.dtypes

test_data.describe()

test_data.isnull().sum()

"""#Feature engineering"""

test_data['transaction_initiation'] = pd.to_datetime(test_data['transaction_initiation'])
test_data['transaction_initiation'].dtypes

test_data['year'] = test_data['transaction_initiation'].dt.year
test_data['month'] = test_data['transaction_initiation'].dt.month
test_data['day'] = test_data['transaction_initiation'].dt.day
test_data['time'] = test_data['transaction_initiation'].dt.time
test_data.drop(columns='transaction_initiation', axis='1', inplace=True)

test_data.head()

test_data.dtypes

test_data=test_data.drop("time",axis=1)
test_data.head()

"""#Preprocessing"""

cat_attr=(["payment_method","partner_category","device_type"])
test_data[cat_attr]=test_data[cat_attr].astype('category')

test_data.dtypes

test_data=test_data.drop(['transaction_number','country'],axis=1)
test_data.head()

"""#Encoding"""

test_data=pd.get_dummies(test_data)

test_data.columns

test_data.shape

train_data.head()

test_data.head()

"""#Merging two datasets """

result_data=pd.merge(train_data,test_data)

result_data.head()

